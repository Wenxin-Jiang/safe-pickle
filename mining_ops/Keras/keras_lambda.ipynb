{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:47:07.317795: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 18:47:07.317857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 18:47:07.336559: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 18:47:07.505539: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 18:47:10.729108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class CustomBiasLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomBiasLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Add a trainable weight for the bias\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='bias'\n",
    "        )\n",
    "        super(CustomBiasLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda_1 (Lambda)           (None, 10)                0         \n",
      "                                                                 \n",
      " custom_bias_layer (CustomB  (None, 10)                10        \n",
      " iasLayer)                                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21 (84.00 Byte)\n",
      "Trainable params: 21 (84.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Lambda\n",
    "\n",
    "# Re-define the model with the custom layer\n",
    "model = Sequential([\n",
    "    Lambda(lambda x: x * 2, input_shape=(10,)),  # Lambda layer\n",
    "    CustomBiasLayer(),  # Custom bias layer\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model summary to see the updated model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(\"keras_lambda_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: keras_lambda_model.h5, Lambda Layers: 1, Custom Layers: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming custom_layers.py contains your custom layer definitions\n",
    "# from custom_layers import CustomLayer1, CustomLayer2\n",
    "\n",
    "def count_layers_in_model(model_path):\n",
    "    # Load the model\n",
    "    model = load_model(model_path, custom_objects={\n",
    "        # 'CustomLayer1': CustomLayer1,\n",
    "        # 'CustomLayer2': CustomLayer2\n",
    "    })\n",
    "    \n",
    "    # Initialize counters\n",
    "    lambda_count = 0\n",
    "    custom_count = 0\n",
    "    \n",
    "    # Iterate through the model's layers\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Lambda):\n",
    "            lambda_count += 1\n",
    "        # Uncomment and modify according to your custom layers\n",
    "        # elif isinstance(layer, (CustomLayer1, CustomLayer2)):\n",
    "        #     custom_count += 1\n",
    "    \n",
    "    return lambda_count, custom_count\n",
    "\n",
    "# List of your .h5 model files\n",
    "model_files = ['keras_lambda_model.h5']\n",
    "\n",
    "# Iterate through the list and count layers for each model\n",
    "for model_file in model_files:\n",
    "    lambda_count, custom_count = count_layers_in_model(model_file)\n",
    "    print(f'Model: {model_file}, Lambda Layers: {lambda_count}, Custom Layers: {custom_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda\n",
      "Dense\n",
      "Model: keras_lambda_model.h5 contains these non-standard layers: []\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "global standard_layer_names\n",
    "\n",
    "def get_standard_keras_layer_names():\n",
    "    layer_names = []\n",
    "    # Iterate through attributes in `layers` module and collect layer names\n",
    "    for attribute_name in dir(layers):\n",
    "        attribute = getattr(layers, attribute_name)\n",
    "        if issubclass(type(attribute), type(tf.keras.layers.Layer)):\n",
    "            layer_names.append(attribute_name)\n",
    "    return layer_names\n",
    "\n",
    "def check_for_custom_layers(model_path):\n",
    "    model = load_model(model_path)\n",
    "    standard_layer_names = get_standard_keras_layer_names()\n",
    "    custom_layers = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        print(layer.__class__.__name__)\n",
    "        if layer.__class__.__name__ not in standard_layer_names:\n",
    "            \n",
    "            custom_layers.append(layer.__class__.__name__)\n",
    "    \n",
    "    return standard_layer_names, custom_layers\n",
    "\n",
    "# Example usage\n",
    "model_files = ['keras_lambda_model.h5']\n",
    "\n",
    "for model_file in model_files:\n",
    "    standard_layer_names, custom_layers = check_for_custom_layers(model_file)\n",
    "    print(f\"Model: {model_file} contains these non-standard layers: {custom_layers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbstractRNNCell', 'Activation', 'ActivityRegularization', 'Add', 'AdditiveAttention', 'AlphaDropout', 'Attention', 'Average', 'AveragePooling1D', 'AveragePooling2D', 'AveragePooling3D', 'AvgPool1D', 'AvgPool2D', 'AvgPool3D', 'BatchNormalization', 'Bidirectional', 'CategoryEncoding', 'CenterCrop', 'Concatenate', 'Conv1D', 'Conv1DTranspose', 'Conv2D', 'Conv2DTranspose', 'Conv3D', 'Conv3DTranspose', 'ConvLSTM1D', 'ConvLSTM2D', 'ConvLSTM3D', 'Convolution1D', 'Convolution1DTranspose', 'Convolution2D', 'Convolution2DTranspose', 'Convolution3D', 'Convolution3DTranspose', 'Cropping1D', 'Cropping2D', 'Cropping3D', 'Dense', 'DenseFeatures', 'DepthwiseConv1D', 'DepthwiseConv2D', 'Discretization', 'Dot', 'Dropout', 'ELU', 'EinsumDense', 'Embedding', 'Flatten', 'GRU', 'GRUCell', 'GaussianDropout', 'GaussianNoise', 'GlobalAveragePooling1D', 'GlobalAveragePooling2D', 'GlobalAveragePooling3D', 'GlobalAvgPool1D', 'GlobalAvgPool2D', 'GlobalAvgPool3D', 'GlobalMaxPool1D', 'GlobalMaxPool2D', 'GlobalMaxPool3D', 'GlobalMaxPooling1D', 'GlobalMaxPooling2D', 'GlobalMaxPooling3D', 'GroupNormalization', 'HashedCrossing', 'Hashing', 'Identity', 'InputLayer', 'InputSpec', 'IntegerLookup', 'LSTM', 'LSTMCell', 'Lambda', 'Layer', 'LayerNormalization', 'LeakyReLU', 'LocallyConnected1D', 'LocallyConnected2D', 'Masking', 'MaxPool1D', 'MaxPool2D', 'MaxPool3D', 'MaxPooling1D', 'MaxPooling2D', 'MaxPooling3D', 'Maximum', 'Minimum', 'MultiHeadAttention', 'Multiply', 'Normalization', 'PReLU', 'Permute', 'RNN', 'RandomBrightness', 'RandomContrast', 'RandomCrop', 'RandomFlip', 'RandomHeight', 'RandomRotation', 'RandomTranslation', 'RandomWidth', 'RandomZoom', 'ReLU', 'RepeatVector', 'Rescaling', 'Reshape', 'Resizing', 'SeparableConv1D', 'SeparableConv2D', 'SeparableConvolution1D', 'SeparableConvolution2D', 'SimpleRNN', 'SimpleRNNCell', 'Softmax', 'SpatialDropout1D', 'SpatialDropout2D', 'SpatialDropout3D', 'SpectralNormalization', 'StackedRNNCells', 'StringLookup', 'Subtract', 'TextVectorization', 'ThresholdedReLU', 'TimeDistributed', 'UnitNormalization', 'UpSampling1D', 'UpSampling2D', 'UpSampling3D', 'Wrapper', 'ZeroPadding1D', 'ZeroPadding2D', 'ZeroPadding3D']\n"
     ]
    }
   ],
   "source": [
    "print(standard_layer_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
